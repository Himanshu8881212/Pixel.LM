torch>=2.0.0
torchvision>=0.15.0
transformers>=4.38.0
datasets>=2.14.0
accelerate>=0.25.0
peft>=0.7.0
trl>=0.7.0
pyyaml>=6.0
einops>=0.7.0
pillow>=10.0.0
tensorboard>=2.14.0
wandb>=0.16.0
pytest>=7.0.0
pytest-cov>=4.0.0
numpy>=1.24.0
requests>=2.31.0
safetensors>=0.4.0

# Production Infrastructure (optional, install as needed)
# flash-attn>=2.5.0          # Flash Attention 3 (CUDA 12.3+, H100/H200)
# deepspeed>=0.14.0          # DeepSpeed ZeRO-3

# NeMo + Megatron (optional, for Stage 1-3)
# nemo_toolkit[all]>=2.0.0   # NeMo 2.0
# megatron-core>=0.7.0       # Megatron Core

# veRL (optional, for Stage 4 GRPO)
# verl>=0.3.0                # ByteDance veRL
# vllm>=0.4.0                # vLLM for rollouts

# FP8 Training (optional, Hopper GPUs only)
# transformer-engine>=1.5.0
